{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ad9fbbb9",
   "metadata": {},
   "source": [
    "Notebook for Twitter Topic Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f335055b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install git+https://github.com/rwalk/gsdmm.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c446750d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gsdmm\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import re\n",
    "\n",
    "from gsdmm import MovieGroupProcess\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c7a6a3b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Unnamed: 0.1</th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>text</th>\n",
       "      <th>processed_text</th>\n",
       "      <th>stripped_text</th>\n",
       "      <th>text_lem</th>\n",
       "      <th>text_tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1630989944289398784</td>\n",
       "      <td>I \"think\" I started my menstrual cycle yesterd...</td>\n",
       "      <td>i \"think\" i started my menstrual cycle yesterd...</td>\n",
       "      <td>think started menstrual cycle yesterday due ab...</td>\n",
       "      <td>think started menstrual cycle yesterday due ab...</td>\n",
       "      <td>['think', 'started', 'menstrual', 'cycle', 'ye...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1630974067875381265</td>\n",
       "      <td>cw menstruation ////\\n.\\n.\\n.\\ni have had my p...</td>\n",
       "      <td>cw menstruation //// . . . i have had my perio...</td>\n",
       "      <td>menstruation period years cycle always month w...</td>\n",
       "      <td>menstruation period years cycle always month w...</td>\n",
       "      <td>['menstruation', 'period', 'years', 'cycle', '...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1630965437709053952</td>\n",
       "      <td>Clubs must ensure that they enhance supportive...</td>\n",
       "      <td>clubs must ensure that they enhance supportive...</td>\n",
       "      <td>clubs must ensure enhance supportive measures ...</td>\n",
       "      <td>clubs must ensure enhance supportive measures ...</td>\n",
       "      <td>['clubs', 'must', 'ensure', 'enhance', 'suppor...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1630878576538013696</td>\n",
       "      <td>#EndPeriodShaming\\nI used to think it was a no...</td>\n",
       "      <td>i used to think it was a normal narrative unt...</td>\n",
       "      <td>used think normal narrative saw orphan girl so...</td>\n",
       "      <td>used think normal narrative saw orphan girl so...</td>\n",
       "      <td>['used', 'think', 'normal', 'narrative', 'saw'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>1630863346143580161</td>\n",
       "      <td>Let’s push for ending period stigma, period po...</td>\n",
       "      <td>let us push for ending period stigma, period p...</td>\n",
       "      <td>let push ending period stigma period poverty p...</td>\n",
       "      <td>let push ending period stigma period poverty p...</td>\n",
       "      <td>['let', 'push', 'ending', 'period', 'stigma', ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  Unnamed: 0.1             tweet_id  \\\n",
       "0           0             0  1630989944289398784   \n",
       "1           1             1  1630974067875381265   \n",
       "2           2             2  1630965437709053952   \n",
       "3           3             3  1630878576538013696   \n",
       "4           4             4  1630863346143580161   \n",
       "\n",
       "                                                text  \\\n",
       "0  I \"think\" I started my menstrual cycle yesterd...   \n",
       "1  cw menstruation ////\\n.\\n.\\n.\\ni have had my p...   \n",
       "2  Clubs must ensure that they enhance supportive...   \n",
       "3  #EndPeriodShaming\\nI used to think it was a no...   \n",
       "4  Let’s push for ending period stigma, period po...   \n",
       "\n",
       "                                      processed_text  \\\n",
       "0  i \"think\" i started my menstrual cycle yesterd...   \n",
       "1  cw menstruation //// . . . i have had my perio...   \n",
       "2  clubs must ensure that they enhance supportive...   \n",
       "3   i used to think it was a normal narrative unt...   \n",
       "4  let us push for ending period stigma, period p...   \n",
       "\n",
       "                                       stripped_text  \\\n",
       "0  think started menstrual cycle yesterday due ab...   \n",
       "1  menstruation period years cycle always month w...   \n",
       "2  clubs must ensure enhance supportive measures ...   \n",
       "3  used think normal narrative saw orphan girl so...   \n",
       "4  let push ending period stigma period poverty p...   \n",
       "\n",
       "                                            text_lem  \\\n",
       "0  think started menstrual cycle yesterday due ab...   \n",
       "1  menstruation period years cycle always month w...   \n",
       "2  clubs must ensure enhance supportive measures ...   \n",
       "3  used think normal narrative saw orphan girl so...   \n",
       "4  let push ending period stigma period poverty p...   \n",
       "\n",
       "                                         text_tokens  \n",
       "0  ['think', 'started', 'menstrual', 'cycle', 'ye...  \n",
       "1  ['menstruation', 'period', 'years', 'cycle', '...  \n",
       "2  ['clubs', 'must', 'ensure', 'enhance', 'suppor...  \n",
       "3  ['used', 'think', 'normal', 'narrative', 'saw'...  \n",
       "4  ['let', 'push', 'ending', 'period', 'stigma', ...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import dataset\n",
    "tweets_df = pd.read_csv('dummy data_processed')\n",
    "tweets_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6d066fee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"['think', 'started', 'menstrual', 'cycle', 'yesterday', 'due', 'ablation', 'surgery', 'working', 'bleeding', 'really', 'bizarre', 'cool', 'always', 'regular', 'track', 'right', 'time', 'period', 'part', 'one', 'still…']\",\n",
       " \"['menstruation', 'period', 'years', 'cycle', 'always', 'month', 'will', 'brain', 'stop', 'convincing', 'pregnant', 'every', 'time', 'hit', 'day', 'cycle']\",\n",
       " \"['clubs', 'must', 'ensure', 'enhance', 'supportive', 'measures', 'women', 'matters', 'menstrual', 'health', 'hygiene', 'management', 'mhm', 'including', 'period', 'tracking', 'free', 'sanitary', 'pads', 'mhm', 'talks', 'internally', 'health', 'experts', 'etc']\"]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a single list of tweet tokens\n",
    "docs = tweets_df['text_tokens'].tolist()\n",
    "docs[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fe3d9816",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In stage 0: transferred 87 clusters with 4 clusters populated\n",
      "In stage 1: transferred 2 clusters with 2 clusters populated\n",
      "In stage 2: transferred 0 clusters with 2 clusters populated\n",
      "In stage 3: transferred 1 clusters with 2 clusters populated\n",
      "In stage 4: transferred 1 clusters with 2 clusters populated\n",
      "In stage 5: transferred 0 clusters with 2 clusters populated\n",
      "In stage 6: transferred 0 clusters with 2 clusters populated\n",
      "In stage 7: transferred 0 clusters with 2 clusters populated\n",
      "In stage 8: transferred 0 clusters with 2 clusters populated\n",
      "In stage 9: transferred 0 clusters with 2 clusters populated\n",
      "In stage 10: transferred 0 clusters with 2 clusters populated\n",
      "In stage 11: transferred 0 clusters with 2 clusters populated\n",
      "In stage 12: transferred 1 clusters with 2 clusters populated\n",
      "In stage 13: transferred 1 clusters with 2 clusters populated\n",
      "In stage 14: transferred 0 clusters with 2 clusters populated\n"
     ]
    }
   ],
   "source": [
    "# Train STTM model\n",
    "mgp = MovieGroupProcess(K=10, alpha=0.1, beta=0.1, n_iters=15)\n",
    "vocab = set(x for doc in docs for x in doc)\n",
    "n_terms = len(vocab)\n",
    "y = mgp.fit(docs, n_terms)\n",
    "\n",
    "# Save model\n",
    "with open('10clusters.model', 'wb') as f:\n",
    "    pickle.dump(mgp, f)\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bb95f60a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load in trained model \n",
    "filehandler = open('10clusters.model', 'rb')\n",
    "mgp = pickle.load(filehandler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "59316c43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define helper functions\n",
    "def top_words(cluster_word_distribution, top_cluster, values):\n",
    "    '''prints the top words in each cluster'''\n",
    "    for cluster in top_cluster:\n",
    "        sort_dicts =sorted(mgp.cluster_word_distribution[cluster].items(), key=lambda k: k[1], reverse=True)[:values]\n",
    "        print('Cluster %s : %s'%(cluster,sort_dicts))\n",
    "        print(' — — — — — — — — —')\n",
    "        \n",
    "def cluster_importance(mgp):\n",
    "    '''returns a word-topic matrix[phi] where each value represents\n",
    "    the word importance for that particular cluster;\n",
    "    phi[i][w] would be the importance of word w in topic i.\n",
    "    '''\n",
    "    n_z_w = mgp.cluster_word_distribution\n",
    "    beta, V, K = mgp.beta, mgp.vocab_size, mgp.K\n",
    "    phi = [{} for i in range(K)]\n",
    "    for z in range(K):\n",
    "        for w in n_z_w[z]:\n",
    "            phi[z][w] = (n_z_w[z][w]+beta)/(sum(n_z_w[z].values())+V*beta)\n",
    "    return phi\n",
    "\n",
    "def topic_allocation(df, docs, mgp, topic_dict):\n",
    "    '''allocates all topics to each document in original dataframe,\n",
    "    adding two columns for cluster number and cluster description'''\n",
    "    topic_allocations = []\n",
    "    for doc in tqdm(docs):\n",
    "        topic_label, score = mgp.choose_best_label(doc)\n",
    "        topic_allocations.append(topic_label)\n",
    "\n",
    "    df['cluster'] = topic_allocations\n",
    "\n",
    "    df['topic_name'] = df.cluster.apply(lambda x: get_topic_name(x, topic_dict))\n",
    "    print('Complete. Number of documents with topic allocated: {}'.format(len(df)))\n",
    "\n",
    "def get_topic_name(doc, topic_dict):\n",
    "    '''returns the topic name string value from a dictionary of topics'''\n",
    "    topic_desc = topic_dict[doc]\n",
    "    return topic_desc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3238b73c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of documents per topic : [ 0  0  0  0  0  0  0  0 87 14]\n",
      "********************\n",
      "Most important clusters (by number of docs inside): [8 9 7 6 5 4 3 2 1 0]\n",
      "********************\n",
      "Cluster 0 : []\n",
      " — — — — — — — — —\n",
      "Cluster 1 : []\n",
      " — — — — — — — — —\n",
      "Cluster 2 : []\n",
      " — — — — — — — — —\n",
      "Cluster 3 : []\n",
      " — — — — — — — — —\n",
      "Cluster 4 : []\n",
      " — — — — — — — — —\n",
      "Cluster 5 : []\n",
      " — — — — — — — — —\n",
      "Cluster 6 : []\n",
      " — — — — — — — — —\n",
      "Cluster 7 : []\n",
      " — — — — — — — — —\n",
      "Cluster 8 : [(\"'\", 3456), (',', 1641), (' ', 1641), ('e', 1217), ('a', 809)]\n",
      " — — — — — — — — —\n",
      "Cluster 9 : [(\"'\", 748), (',', 360), (' ', 360), ('e', 263), ('a', 211)]\n",
      " — — — — — — — — —\n"
     ]
    }
   ],
   "source": [
    "doc_count = np.array(mgp.cluster_doc_count)\n",
    "print('Number of documents per topic :', doc_count)\n",
    "print('*'*20)\n",
    "\n",
    "# topics sorted by the number of documents they are allocated to\n",
    "top_index = doc_count.argsort()[-10:][::-1]\n",
    "print('Most important clusters (by number of docs inside):', top_index)\n",
    "print('*'*20)\n",
    "\n",
    "# show the top 5 words in term frequency for each cluster \n",
    "topic_indices = np.arange(start=0, stop=len(doc_count), step=1)\n",
    "top_words(mgp.cluster_word_distribution, topic_indices, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9848b804",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
