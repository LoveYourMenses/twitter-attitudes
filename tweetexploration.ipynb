{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "94808a92",
   "metadata": {},
   "source": [
    "Notebook for Tweet Cleaning and Initial Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f20621f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install wordcloud\n",
    "!pip install plotly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89ac5701",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import packages **need to filter through and only import what's needed for this part\n",
    "import re\n",
    "import string\n",
    "import collections\n",
    "import ipywidgets\n",
    "import cufflinks\n",
    "import nltk.tokenize\n",
    "\n",
    "import plotly.offline as py\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.font_manager as fm\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk.probability import FreqDist\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import stopwords\n",
    "from wordcloud import WordCloud, STOPWORDS, ImageColorGenerator\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05ea97ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_colwidth', None)\n",
    "\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('omw-1.4')\n",
    "\n",
    "cufflinks.go_offline()\n",
    "cufflinks.set_config_file(world_readable=True, theme='pearl')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a874881e",
   "metadata": {},
   "source": [
    "Cleaning Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8b91a11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import raw dataset\n",
    "tweets_df = pd.read_csv('dummy data.csv')\n",
    "tweets_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e516b532",
   "metadata": {},
   "outputs": [],
   "source": [
    "def processed(text):\n",
    "    # Remove links\n",
    "    text = re.sub('http://\\S+|https://\\S+', '', text)\n",
    "    text = re.sub('http[s]?://\\S+', '', text)\n",
    "    text = re.sub(r\"http\\S+\", \"\", text)\n",
    "\n",
    "    # Convert HTML references\n",
    "    text = re.sub('&amp', 'and', text)\n",
    "    text = re.sub('&lt', '<', text)\n",
    "    text = re.sub('&gt', '>', text)\n",
    "    text = re.sub('\\xao', ' ', text)\n",
    "\n",
    "    # Remove new line characters\n",
    "    text = re.sub('[\\r\\n]+', ' ', text)\n",
    "    \n",
    "    # Remove mentions\n",
    "    text = re.sub(r'@\\w+', '', text)\n",
    "    \n",
    "    # Remove hashtags\n",
    "    text = re.sub(r'#\\w+', '', text)\n",
    "\n",
    "    # Remove multiple space characters\n",
    "    text = re.sub('\\s+',' ', text)\n",
    "    \n",
    "    # Convert to lowercase\n",
    "    text = text.lower()\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f806795f",
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_df['processed_text'] = tweets_df['text'].apply(processed)\n",
    "tweets_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be2760a3",
   "metadata": {},
   "source": [
    "Hashtags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09781a19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create list of all hashtags in dataset\n",
    "hashtags_list = []\n",
    "\n",
    "for tweet in tweets_df['text']:\n",
    "    # Extract hashtags from tweet content\n",
    "    hashtags = re.findall(r\"#\\w+\", tweet[2])\n",
    "    # Append hashtags to list\n",
    "    hashtags_list.extend(hashtags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dff5bf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count and visualize the most common hashtags present in the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2078516c",
   "metadata": {},
   "source": [
    "Mentions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c97e324",
   "metadata": {},
   "source": [
    "Unigrams (incl. worldcloud w/wo keywords)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68db5ca5",
   "metadata": {},
   "source": [
    "Bi-grams"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86a0c6e8",
   "metadata": {},
   "source": [
    "Tri-grams"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
